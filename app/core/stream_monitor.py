"""
app/core/stream_monitor.py - æµå¼ç›‘å¬æ ¸å¿ƒï¼ˆv5.5 å›¾ç‰‡æ”¯æŒç‰ˆï¼‰

v5.5 ä¿®æ”¹ï¼š
- æ·»åŠ å›¾ç‰‡æ£€æµ‹ï¼ˆå¿«ç…§ä¸­åŒ…å« image_countï¼‰
- _detect_ai_start() æ”¯æŒå›¾ç‰‡å‡ºç°æ£€æµ‹
- æœ€ç»ˆé˜¶æ®µè‡ªåŠ¨æå–å›¾ç‰‡
- æ–°å¢ _image_config é…ç½®æ”¯æŒ
"""

import time
import threading
from typing import Generator, Optional, Callable, Tuple, Dict, List, Any

from app.core.config import logger, BrowserConstants, SSEFormatter
from app.core.elements import ElementFinder
from app.core.extractors.base import BaseExtractor
from app.core.extractors.deep_mode import DeepBrowserExtractor


class StreamContext:
    """æµå¼ç›‘æ§ä¸Šä¸‹æ–‡ï¼ˆv5.5 å¢åŠ å›¾ç‰‡è¿½è¸ªï¼‰"""
    def __init__(self):
        self.max_seen_text = ""
        self.sent_content_length = 0

        self.baseline_snapshot = None
        self.active_turn_started = False
        self.stable_text_count = 0
        self.last_stable_text = ""
        self.active_turn_baseline_len = 0

        # ä¸¤é˜¶æ®µ baseline
        self.instant_baseline = None
        self.user_baseline = None
        
        # v5.4ï¼šè®°å½• instant é˜¶æ®µæœ€åä¸€ä¸ªèŠ‚ç‚¹çš„é•¿åº¦
        self.instant_last_node_len = 0
        
        # v5.5 æ–°å¢ï¼šå›¾ç‰‡è¿½è¸ª
        self.baseline_image_count = 0
        self.images_detected = False

        # çŠ¶æ€æ ‡è®°
        self.content_ever_changed = False
        self.user_msg_confirmed = False

        # è¾“å‡ºç›®æ ‡é”å®š
        self.output_target_anchor = None
        self.output_target_count = 0
        self.pending_new_anchor = None
        self.pending_new_anchor_seen = 0

    def reset_for_new_target(self):
        """åˆ‡æ¢åˆ°æ–°ç›®æ ‡èŠ‚ç‚¹æ—¶é‡ç½®çŠ¶æ€"""
        self.max_seen_text = ""
        self.sent_content_length = 0
        self.stable_text_count = 0
        self.last_stable_text = ""
        self.active_turn_baseline_len = 0
        self.content_ever_changed = False
        # v5.5: ä¸é‡ç½® images_detectedï¼Œä¿æŒå›¾ç‰‡æ£€æµ‹çŠ¶æ€

    def calculate_diff(self, current_text: str) -> Tuple[str, bool, Optional[str]]:
        """v5 å¢å¼ºç‰ˆ diffï¼šæ”¯æŒå‰ç¼€æ ¡éªŒ"""
        if not current_text:
            return "", False, None

        effective_start = self.active_turn_baseline_len + self.sent_content_length

        # ğŸ†• å‰ç¼€ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆå¦‚æœå·²å‘é€è¿‡å†…å®¹ï¼‰
        if self.sent_content_length > 0 and len(current_text) >= effective_start:
            sent_prefix_end = self.active_turn_baseline_len + self.sent_content_length
            
            # è·å–å·²å‘é€éƒ¨åˆ†å¯¹åº”çš„å½“å‰æ–‡æœ¬
            current_sent_part = current_text[self.active_turn_baseline_len:sent_prefix_end]
            
            # ä¸å†å²è®°å½•æ¯”å¯¹
            if self.max_seen_text and len(self.max_seen_text) >= sent_prefix_end:
                expected_sent_part = self.max_seen_text[self.active_turn_baseline_len:sent_prefix_end]
                
                # æ£€æµ‹å‰ç¼€ä¸åŒ¹é…
                if current_sent_part != expected_sent_part:
                    # å®¹é”™ï¼šåªæœ‰å·®å¼‚è¶…è¿‡ 5% æ‰è®¤ä¸ºæ˜¯çœŸå®ä¸åŒ¹é…ï¼ˆå®¹å¿å¾®å°å˜åŒ–ï¼‰
                    mismatch_threshold = max(10, len(expected_sent_part) * 0.05)
                    
                    mismatch_count = sum(
                        1 for i in range(min(len(current_sent_part), len(expected_sent_part)))
                        if i < len(current_sent_part) and i < len(expected_sent_part)
                        and current_sent_part[i] != expected_sent_part[i]
                    )
                    
                    if mismatch_count > mismatch_threshold:
                        logger.warning(
                            f"[PREFIX_MISMATCH] æ£€æµ‹åˆ°å†…å®¹é‡å†™ "
                            f"(mismatch={mismatch_count}/{len(expected_sent_part)})"
                        )
                        return "", False, "prefix_mismatch"

        # åŸæœ‰é€»è¾‘ï¼šé•¿åº¦å¢é•¿
        if len(current_text) > effective_start:
            diff = current_text[effective_start:]
            return diff, False, None

        # åŸæœ‰é€»è¾‘ï¼šå†…å®¹ç¼©çŸ­æ£€æµ‹
        if len(current_text) >= self.active_turn_baseline_len:
            current_active_text = current_text[self.active_turn_baseline_len:]
            if len(current_active_text) < self.sent_content_length:
                shrink_amount = self.sent_content_length - len(current_active_text)
                if shrink_amount <= BrowserConstants.STREAM_CONTENT_SHRINK_TOLERANCE:
                    return "", False, None
                return "", False, f"å†…å®¹ç¼©çŸ­ {shrink_amount} å­—ç¬¦"

        # åŸæœ‰é€»è¾‘ï¼šå†å²å¿«ç…§å›é€€
        if self.max_seen_text and len(self.max_seen_text) > effective_start:
            diff = self.max_seen_text[effective_start:]
            return diff, True, "ä½¿ç”¨å†å²å¿«ç…§"

        return "", False, None

    def update_after_send(self, diff: str, current_text: str):
        self.sent_content_length += len(diff)
        self.last_stable_text = current_text
        self.stable_text_count = 0

        if len(current_text) > len(self.max_seen_text):
            self.max_seen_text = current_text


class GeneratingStatusCache:
    """ç”ŸæˆçŠ¶æ€ç¼“å­˜"""

    def __init__(self, tab):
        self.tab = tab
        self._last_check_time = 0.0
        self._last_result = False
        self._check_interval = 0.5
        self._found_selector = None

    def is_generating(self) -> bool:
        now = time.time()
        if now - self._last_check_time < self._check_interval:
            return self._last_result

        self._last_check_time = now

        if self._found_selector:
            try:
                ele = self.tab.ele(self._found_selector, timeout=0.1)
                if ele and ele.states.is_displayed:
                    self._last_result = True
                    return True
            except Exception:
                pass
            self._found_selector = None

        indicator_selectors = [
            'css:button[aria-label*="Stop"]',
            'css:button[aria-label*="stop"]',
            'css:[data-state="streaming"]',
            'css:.stop-generating',
        ]

        for selector in indicator_selectors:
            try:
                ele = self.tab.ele(selector, timeout=0.05)
                if ele and ele.states.is_displayed:
                    self._found_selector = selector
                    self._last_result = True
                    return True
            except Exception:
                pass

        self._last_result = False
        return False


class StreamMonitor:
    """æµå¼ç›‘å¬å™¨ï¼ˆv5.5 å›¾ç‰‡æ”¯æŒç‰ˆ + å¯é…ç½®è¶…æ—¶ï¼‰"""
    
    DEFAULT_HARD_TIMEOUT = 300  # é»˜è®¤ç¡¬è¶…æ—¶ï¼ˆç§’ï¼‰
    BASELINE_POLLUTION_THRESHOLD = 20

    def __init__(self, tab, finder: ElementFinder, formatter: SSEFormatter,
                 stop_checker: Optional[Callable[[], bool]] = None,
                 extractor: Optional[BaseExtractor] = None,
                 image_config: Optional[Dict] = None,
                 stream_config: Optional[Dict] = None):  # ğŸ†• æ–°å¢æµå¼é…ç½®
        self.tab = tab
        self.finder = finder
        self.formatter = formatter
        self._should_stop = stop_checker or (lambda: False)
        self.extractor = extractor if extractor is not None else DeepBrowserExtractor()
        
        # å›¾ç‰‡é…ç½®
        self._image_config = image_config or {}
        self._image_extraction_enabled = self._image_config.get("enabled", False)
        
        # ğŸ†• æµå¼é…ç½®ï¼ˆæ”¯æŒç«™ç‚¹çº§è¦†ç›–ï¼‰
        self._stream_config = stream_config or {}
        self._hard_timeout = self._stream_config.get(
            "hard_timeout", 
            self.DEFAULT_HARD_TIMEOUT
        )

        self._stream_ctx: Optional[StreamContext] = None
        self._final_complete_text = ""
        self._final_images: List[Dict] = []
        self._generating_checker: Optional[GeneratingStatusCache] = None

    def monitor(self, selector: str, user_input: str = "",
                completion_id: Optional[str] = None) -> Generator[str, None, None]:
        logger.debug("æµå¼ç›‘å¬å¯åŠ¨")
        logger.debug(f"[MONITOR] selector_raw={selector!r}, image_enabled={self._image_extraction_enabled}")
        
        if completion_id is None:
            completion_id = SSEFormatter._generate_id()

        ctx = StreamContext()
        self._stream_ctx = ctx
        self._final_images = []
        self._generating_checker = GeneratingStatusCache(self.tab)

        # ===== é˜¶æ®µ 0ï¼šinstant baseline =====
        ctx.instant_baseline = self._get_latest_message_snapshot(selector)
        ctx.instant_last_node_len = ctx.instant_baseline.get('text_len', 0)
        ctx.baseline_image_count = ctx.instant_baseline.get('image_count', 0)  # ğŸ†•
        
        logger.debug(
            f"[Instant] count={ctx.instant_baseline['groups_count']}, "
            f"last_node_len={ctx.instant_last_node_len}, "
            f"images={ctx.baseline_image_count}"  # ğŸ†•
        )

        # ===== é˜¶æ®µ 1ï¼šç­‰å¾…ç”¨æˆ·æ¶ˆæ¯ä¸Šå± =====
        user_msg_wait_start = time.time()
        user_msg_wait_max = BrowserConstants.STREAM_USER_MSG_WAIT
        ctx.user_baseline = None

        while time.time() - user_msg_wait_start < user_msg_wait_max:
            if self._should_stop():
                logger.info("ç­‰å¾…ç”¨æˆ·æ¶ˆæ¯æ—¶è¢«å–æ¶ˆ")
                return

            current_snapshot = self._get_latest_message_snapshot(selector)
            current_count = current_snapshot['groups_count']
            current_text_len = current_snapshot.get('text_len', 0)
            current_image_count = current_snapshot.get('image_count', 0)  # ğŸ†•
            instant_count = ctx.instant_baseline['groups_count']

            if current_count == instant_count + 1:
                logger.debug(f"ç”¨æˆ·æ¶ˆæ¯ä¸Šå± ({instant_count} -> {current_count})")
                ctx.user_msg_confirmed = True
                ctx.user_baseline = current_snapshot
                
                pollution_delta = current_text_len - ctx.instant_last_node_len
                if pollution_delta > self.BASELINE_POLLUTION_THRESHOLD:
                    logger.debug("AI æé€Ÿå›å¤")
                    ctx.active_turn_started = True
                    ctx.active_turn_baseline_len = ctx.instant_last_node_len
                else:
                    if pollution_delta > 0:
                        logger.info(f"[Quick Start] æ£€æµ‹åˆ°å¿«é€Ÿå›å¤ï¼ˆ{pollution_delta} å­—ç¬¦ï¼‰ï¼Œç«‹å³å¼€å§‹ç›‘æ§")
                        ctx.active_turn_started = True
                        ctx.active_turn_baseline_len = ctx.instant_last_node_len
                
                break

            elif current_count >= instant_count + 2:
                logger.info(f"[Fast AI] AI ç§’å› (count: {instant_count} -> {current_count})")
                ctx.user_baseline = current_snapshot
                ctx.user_msg_confirmed = True
                ctx.active_turn_started = True
                ctx.active_turn_baseline_len = 0
                break

            elif current_count == instant_count:
                # ğŸ†• æ£€æµ‹å›¾ç‰‡å‡ºç°
                if current_image_count > ctx.baseline_image_count:
                    logger.info(f"[Image Detected] æ£€æµ‹åˆ°æ–°å›¾ç‰‡ ({ctx.baseline_image_count} -> {current_image_count})")
                    ctx.user_baseline = current_snapshot
                    ctx.user_msg_confirmed = True
                    ctx.active_turn_started = True
                    ctx.active_turn_baseline_len = ctx.instant_last_node_len
                    ctx.images_detected = True
                    break
                
                if current_text_len > ctx.instant_last_node_len + 10:
                    logger.debug("[Same Node] åŒèŠ‚ç‚¹æ–‡æœ¬å¢é•¿ï¼Œå¯èƒ½ä¸º AI å›å¤")
                    ctx.user_baseline = current_snapshot
                    ctx.user_msg_confirmed = True
                    ctx.active_turn_started = True
                    ctx.active_turn_baseline_len = ctx.instant_last_node_len
                    break

            time.sleep(0.2)

        if ctx.user_baseline is None:
            logger.debug("[Timeout] æœªæ£€æµ‹åˆ°ç”¨æˆ·æ¶ˆæ¯ä¸Šå±ï¼Œä½¿ç”¨ instant baseline")
            ctx.user_baseline = ctx.instant_baseline

        # ===== é˜¶æ®µ 2ï¼šç­‰å¾… AI å¼€å§‹ =====
        if not ctx.active_turn_started:
            baseline = ctx.user_baseline
            start_time = time.time()

            while True:
                if self._should_stop():
                    logger.info("ç­‰å¾…AIå¼€å§‹æ—¶è¢«å–æ¶ˆ")
                    return

                elapsed = time.time() - start_time
                current = self._get_latest_message_snapshot(selector)

                is_started, reason = self._detect_ai_start(baseline, current, ctx)  # ğŸ†• ä¼ å…¥ ctx
                if is_started:
                    logger.debug(f"AI å¼€å§‹å›å¤: {reason}")
                    ctx.active_turn_started = True

                    if current['groups_count'] > baseline['groups_count']:
                        ctx.active_turn_baseline_len = 0
                    else:
                        ctx.active_turn_baseline_len = baseline.get('text_len', 0)
                    
                    break

                if elapsed > BrowserConstants.STREAM_INITIAL_WAIT:
                    logger.warning(f"[Timeout] ç­‰å¾… AI å¼€å§‹è¶…æ—¶ï¼ˆ{elapsed:.1f}sï¼‰")
                    break

                time.sleep(0.3)

        # ===== é˜¶æ®µ 3ï¼šå¢é‡è¾“å‡º =====
        if ctx.active_turn_started:
            yield from self._stream_output_phase(selector, ctx, completion_id=completion_id)
        else:
            logger.warning("[Exit] æœªæ£€æµ‹åˆ° AI å›å¤ï¼Œé€€å‡ºç›‘æ§")

    def _get_latest_message_snapshot(self, selector: str) -> dict:
        """å–æœ€åä¸€ä¸ªèŠ‚ç‚¹å¿«ç…§ï¼ˆv5.5ï¼šåŒ…å«å›¾ç‰‡æ£€æµ‹ï¼‰"""
        result = {
            'groups_count': 0, 
            'anchor': None, 
            'text': '', 
            'text_len': 0, 
            'is_generating': False,
            'image_count': 0,      # ğŸ†•
            'has_images': False    # ğŸ†•
        }
        try:
            eles = self.finder.find_all(selector, timeout=0.5)
            if not eles:
                return result

            last_ele = eles[-1]
            text = self.extractor.extract_text(last_ele)

            result['groups_count'] = len(eles)
            result['text'] = text or ""
            result['text_len'] = len(result['text'])
            result['anchor'] = self.extractor.get_anchor(last_ele)

            # ğŸ†• å›¾ç‰‡æ£€æµ‹ï¼ˆè½»é‡çº§ï¼Œåªè®¡æ•°ï¼‰
            try:
                img_count = last_ele.run_js("""
                    return (this.querySelectorAll('img') || []).length;
                """) or 0
                result['image_count'] = int(img_count)
                result['has_images'] = img_count > 0
            except Exception as e:
                logger.debug(f"å›¾ç‰‡è®¡æ•°å¤±è´¥: {e}")

            if self._generating_checker is None:
                self._generating_checker = GeneratingStatusCache(self.tab)
            result['is_generating'] = self._generating_checker.is_generating()

        except Exception as e:
            logger.debug(f"Snapshot å¼‚å¸¸: {e}")
        return result

    def _get_snapshot_prefer_anchor(self, selector: str, prefer_anchor: Optional[str]) -> dict:
        """æŒ‰é”šç‚¹é”å®šè¯»å–ç›®æ ‡å…ƒç´ ï¼ˆv5.5ï¼šåŒ…å«å›¾ç‰‡æ£€æµ‹ï¼‰"""
        result = {
            'groups_count': 0, 
            'anchor': None, 
            'text': '', 
            'text_len': 0, 
            'is_generating': False,
            'image_count': 0,      # ğŸ†•
            'has_images': False    # ğŸ†•
        }
        try:
            eles = self.finder.find_all(selector, timeout=0.5)
            if not eles:
                return result

            result['groups_count'] = len(eles)

            target = None
            target_anchor = None

            if prefer_anchor:
                for ele in reversed(eles):
                    a = self.extractor.get_anchor(ele)
                    if a == prefer_anchor:
                        target = ele
                        target_anchor = a
                        break

            if target is None:
                target = eles[-1]
                target_anchor = self.extractor.get_anchor(target)
                
                last_text = self.extractor.extract_text(target)
                if (not last_text or not last_text.strip()) and len(eles) >= 2:
                    logger.debug(f"[Empty Last] æœ€åä¸€ä¸ªå…ƒç´ ä¸ºç©ºï¼Œå…± {len(eles)} ä¸ªå…ƒç´ ")

            text = self.extractor.extract_text(target) or ""

            result['anchor'] = target_anchor
            result['text'] = text
            result['text_len'] = len(text)

            # ğŸ†• å›¾ç‰‡æ£€æµ‹
            try:
                img_count = target.run_js("return (this.querySelectorAll('img') || []).length;") or 0
                result['image_count'] = int(img_count)
                result['has_images'] = img_count > 0
            except Exception:
                pass

            if self._generating_checker is None:
                self._generating_checker = GeneratingStatusCache(self.tab)
            result['is_generating'] = self._generating_checker.is_generating()

        except Exception as e:
            logger.debug(f"Prefer-anchor Snapshot å¼‚å¸¸: {e}")

        return result

    def _get_active_turn_text(self, selector: str) -> str:
        """å›é€€ï¼šå–æœ€åä¸€ä¸ªå…ƒç´ çš„æ–‡æœ¬"""
        try:
            eles = self.finder.find_all(selector, timeout=1)
            if not eles:
                return ""
            
            last_text = self.extractor.extract_text(eles[-1])
            if last_text and last_text.strip():
                return last_text.strip()
            
            for i in range(len(eles) - 2, -1, -1):
                t = self.extractor.extract_text(eles[i])
                if t and t.strip():
                    return t.strip()
            
            return ""
        except Exception:
            return ""

    def _detect_ai_start(self, baseline: dict, current: dict, ctx: StreamContext) -> Tuple[bool, str]:
        """æ£€æµ‹ AI æ˜¯å¦å¼€å§‹å›å¤ï¼ˆv5.5ï¼šæ”¯æŒå›¾ç‰‡æ£€æµ‹ï¼‰"""
        
        if current['groups_count'] > baseline['groups_count']:
            return True, f"èŠ‚ç‚¹æ•°å¢åŠ  {current['groups_count'] - baseline['groups_count']}"
        
        if current['is_generating']:
            return True, "ç”ŸæˆæŒ‡ç¤ºå™¨æ¿€æ´»"
        
        if current['text_len'] > baseline['text_len'] + 10:
            return True, f"æ–‡æœ¬å¢é•¿ {current['text_len'] - baseline['text_len']} å­—ç¬¦"
        
        # ğŸ†• å›¾ç‰‡æ£€æµ‹ï¼šå³ä½¿æ²¡æœ‰æ–‡æœ¬å¢é•¿ï¼Œæœ‰å›¾ç‰‡å‡ºç°ä¹Ÿè®¤ä¸ºå¼€å§‹å›å¤
        current_img = current.get('image_count', 0)
        baseline_img = baseline.get('image_count', 0)
        if current_img > baseline_img:
            ctx.images_detected = True
            return True, f"æ£€æµ‹åˆ°æ–°å›¾ç‰‡ ({baseline_img} -> {current_img})"
        
        return False, ""

    def _stream_output_phase(self, selector: str, ctx: StreamContext,
                             completion_id: Optional[str] = None) -> Generator[str, None, None]:
        """æµå¼è¾“å‡ºé˜¶æ®µï¼ˆv5.5ï¼šå¢åŠ å›¾ç‰‡å˜åŒ–æ£€æµ‹ï¼‰"""
        silence_start = time.time()
        has_output = False

        current_interval = BrowserConstants.STREAM_CHECK_INTERVAL_DEFAULT
        min_interval = BrowserConstants.STREAM_CHECK_INTERVAL_MIN
        max_interval = BrowserConstants.STREAM_CHECK_INTERVAL_MAX

        element_missing_count = 0
        max_element_missing = 10

        last_text_len = 0
        last_image_count = ctx.baseline_image_count  # ğŸ†•
        
        phase_start = time.time()

        initial_snap = self._get_snapshot_prefer_anchor(selector, None)
        ctx.output_target_count = initial_snap['groups_count']
        ctx.output_target_anchor = initial_snap['anchor']

        peak_text_len = 0
        content_shrink_count = 0

        while True:
            if time.time() - phase_start > self._hard_timeout:
                logger.error(f"[HardTimeout] è¶…è¿‡æœ€å¤§ç›‘å¬æ—¶é—´ {self._hard_timeout}sï¼Œå¼ºåˆ¶é€€å‡º")
                break
            
            if self._should_stop():
                logger.info("è¾“å‡ºé˜¶æ®µè¢«å–æ¶ˆ")
                break

            snap = self._get_snapshot_prefer_anchor(selector, ctx.output_target_anchor)

            current_count = snap['groups_count']
            current_anchor = snap['anchor']
            current_text = snap['text'] or ""
            still_generating = snap['is_generating']
            current_text_len = len(current_text)
            current_image_count = snap.get('image_count', 0)  # ğŸ†•
            
            # ğŸ†• æ£€æµ‹å›¾ç‰‡å˜åŒ–
            if current_image_count > last_image_count:
                logger.debug(f"[Image Change] å›¾ç‰‡æ•°é‡å˜åŒ–: {last_image_count} -> {current_image_count}")
                ctx.images_detected = True
                ctx.content_ever_changed = True
                silence_start = time.time()  # é‡ç½®é™é»˜è®¡æ—¶
                last_image_count = current_image_count

            # æ£€æµ‹å†…å®¹æŠ˜å 
            if current_text_len > peak_text_len:
                peak_text_len = current_text_len
                content_shrink_count = 0
            elif peak_text_len > 100 and current_text_len < peak_text_len * 0.5:
                content_shrink_count += 1
                if content_shrink_count >= 2:
                    logger.info(f"[Collapse] æ£€æµ‹åˆ°å†…å®¹æŠ˜å ï¼š{peak_text_len} -> {current_text_len}")
                    ctx.reset_for_new_target()
                    peak_text_len = current_text_len
                    content_shrink_count = 0
                    silence_start = time.time()
                    has_output = False
                    last_text_len = current_text_len
                    time.sleep(0.2)
                    continue
            else:
                content_shrink_count = 0

            # æ£€æµ‹æ–°èŠ‚ç‚¹å‡ºç°
            if current_count > ctx.output_target_count:
                if current_anchor != ctx.output_target_anchor:
                    if ctx.pending_new_anchor == current_anchor:
                        ctx.pending_new_anchor_seen += 1
                    else:
                        ctx.pending_new_anchor = current_anchor
                        ctx.pending_new_anchor_seen = 1

                    if ctx.pending_new_anchor_seen >= 2:
                        ctx.reset_for_new_target()
                        peak_text_len = 0
                        silence_start = time.time()
                        has_output = False
                        last_text_len = 0
                        last_image_count = 0  # ğŸ†•

                        if not current_text:
                            time.sleep(0.2)
                            continue
            else:
                ctx.pending_new_anchor = None
                ctx.pending_new_anchor_seen = 0

            # ç©ºæ–‡æœ¬å¤„ç†
            if not current_text:
                # ğŸ†• å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ ‡è®°å†…å®¹å˜åŒ–å¹¶ç»§ç»­æ£€æŸ¥é€€å‡ºæ¡ä»¶
                if snap.get('has_images'):
                    ctx.content_ever_changed = True
                    # ä¸ continueï¼Œç»§ç»­æ‰§è¡Œåé¢çš„é€€å‡ºåˆ¤å®šé€»è¾‘
                else:
                    if ctx.sent_content_length > 0:
                        element_missing_count += 1
                        if element_missing_count >= max_element_missing:
                            logger.warning("å…ƒç´ æŒç»­ä¸¢å¤±ï¼Œé€€å‡ºç›‘æ§")
                            break
                    time.sleep(0.2)
                    continue
            else:
                element_missing_count = 0

            if len(current_text) > len(ctx.max_seen_text):
                ctx.max_seen_text = current_text

            diff, is_from_history, reason = ctx.calculate_diff(current_text)
            
            # ğŸ†• å¤„ç†å‰ç¼€ä¸åŒ¹é…ï¼ˆå†…å®¹è¢«é‡å†™ï¼‰
            if reason == "prefix_mismatch":
                logger.info("[PREFIX_MISMATCH] å†…å®¹é‡å†™ï¼Œå‘é€å®Œæ•´å½“å‰å†…å®¹")
                
                # é‡ç½®å‘é€çŠ¶æ€
                ctx.sent_content_length = 0
                ctx.max_seen_text = ""
                
                # å‘é€å½“å‰å®Œæ•´å†…å®¹
                full_content = current_text[ctx.active_turn_baseline_len:]
                if full_content:
                    yield self.formatter.pack_chunk(full_content, completion_id=completion_id)
                    ctx.update_after_send(full_content, current_text)
                    silence_start = time.time()
                    has_output = True
                    ctx.content_ever_changed = True
                
                continue
            
            if diff:
                if self._should_stop():
                    break
                ctx.update_after_send(diff, current_text)
                silence_start = time.time()
                has_output = True
                current_interval = min_interval
                ctx.content_ever_changed = True

                yield self.formatter.pack_chunk(diff, completion_id=completion_id)
            else:
                if current_text == ctx.last_stable_text:
                    ctx.stable_text_count += 1
                else:
                    ctx.stable_text_count = 0
                    ctx.last_stable_text = current_text
                current_interval = min(current_interval * 1.5, max_interval)

            if current_text_len != last_text_len:
                ctx.content_ever_changed = True
                last_text_len = current_text_len

            silence_duration = time.time() - silence_start

            # é€€å‡ºåˆ¤å®š
            silence_threshold = BrowserConstants.STREAM_SILENCE_THRESHOLD
            silence_threshold_fallback = BrowserConstants.STREAM_SILENCE_THRESHOLD_FALLBACK
            stable_count_threshold = BrowserConstants.STREAM_STABLE_COUNT_THRESHOLD

            if ctx.content_ever_changed:
                if (ctx.stable_text_count >= stable_count_threshold and
                        silence_duration > silence_threshold):
                    logger.debug(f"ç”Ÿæˆç»“æŸ (ç¨³å®š{ctx.stable_text_count}æ¬¡, é™é»˜{silence_duration:.1f}s)")
                    break
                elif silence_duration > silence_threshold_fallback * 3:
                    logger.info(f"[Exit] ç”Ÿæˆç»“æŸï¼ˆè¶…é•¿é™é»˜ {silence_duration:.1f}sï¼‰")
                    break
                elif ctx.images_detected and silence_duration > 3.0:
                    # æœ‰å›¾ç‰‡ä¸”é™é»˜è¶…è¿‡ 3 ç§’ï¼Œè®¤ä¸ºç”Ÿæˆå®Œæˆ
                    logger.debug(f"[Exit] å›¾ç‰‡ç”Ÿæˆå®Œæˆï¼ˆé™é»˜ {silence_duration:.1f}sï¼‰")
                    break
            else:
                if not still_generating and not has_output:
                    # ğŸ†• å¦‚æœæœ‰å›¾ç‰‡ä½†æ²¡æ–‡æœ¬ï¼Œä¹Ÿè®¤ä¸ºæ˜¯æœ‰æ•ˆå›å¤
                    if ctx.images_detected or current_text_len > ctx.active_turn_baseline_len + 5:
                        logger.info("[Exit] æ£€æµ‹åˆ°å¿«é€Ÿå›å¤ï¼ˆæ— å¢é‡ä½†æœ‰æœ€ç»ˆå†…å®¹/å›¾ç‰‡ï¼‰")
                        break

            sleep_elapsed = 0.0
            while sleep_elapsed < current_interval:
                if self._should_stop():
                    break
                step = min(0.1, current_interval - sleep_elapsed)
                time.sleep(step)
                sleep_elapsed += step

        if not self._should_stop():
            yield from self._final_settle_and_output(selector, ctx, completion_id=completion_id)

    def _final_settle_and_output(self, selector: str, ctx: StreamContext,
                                 completion_id: Optional[str] = None) -> Generator[str, None, None]:
        """æœ€ç»ˆé˜¶æ®µï¼ˆv5.5ï¼šåŒ…å«å›¾ç‰‡æå–ï¼‰"""
        settle_time = 1.5
        hardcap = 5.0

        start = time.time()
        stable_start = time.time()

        last_snap = self._get_snapshot_prefer_anchor(selector, ctx.output_target_anchor)

        while True:
            if self._should_stop():
                break
            now = time.time()
            if now - start > hardcap:
                break
            if now - stable_start >= settle_time:
                break

            time.sleep(0.15)
            snap = self._get_snapshot_prefer_anchor(selector, ctx.output_target_anchor)

            changed = False
            if snap['groups_count'] > last_snap['groups_count']:
                changed = True
                if snap['anchor'] != ctx.output_target_anchor:
                    ctx.output_target_anchor = snap['anchor']
                    ctx.output_target_count = snap['groups_count']
                    ctx.reset_for_new_target()
                    last_snap = snap
                    stable_start = time.time()
                    continue

            if snap['text_len'] != last_snap['text_len']:
                changed = True
            if snap['anchor'] != last_snap['anchor']:
                changed = True
            # ğŸ†• å›¾ç‰‡å˜åŒ–ä¹Ÿç®— changed
            if snap.get('image_count', 0) != last_snap.get('image_count', 0):
                changed = True

            if changed:
                stable_start = time.time()
            last_snap = snap

        final_snap = self._get_snapshot_prefer_anchor(selector, ctx.output_target_anchor)
        final_text = final_snap.get('text', "") or ""

        # æ–‡æœ¬è¡¥é½
        if final_text:
            final_effective_start = ctx.active_turn_baseline_len + ctx.sent_content_length
            if len(final_text) > final_effective_start:
                remaining = final_text[final_effective_start:]
                if remaining:
                    logger.debug(f"[Final] å‘é€å‰©ä½™å†…å®¹: {len(remaining)} å­—ç¬¦")
                    yield self.formatter.pack_chunk(remaining, completion_id=completion_id)
                    ctx.sent_content_length += len(remaining)

            self._final_complete_text = final_text[ctx.active_turn_baseline_len:]
        else:
            fallback_text = self._get_active_turn_text(selector)
            if fallback_text:
                final_effective_start = ctx.active_turn_baseline_len + ctx.sent_content_length
                if len(fallback_text) > final_effective_start:
                    remaining = fallback_text[final_effective_start:]
                    if remaining:
                        yield self.formatter.pack_chunk(remaining, completion_id=completion_id)
                        ctx.sent_content_length += len(remaining)

                self._final_complete_text = fallback_text[ctx.active_turn_baseline_len:]
            else:
                self._final_complete_text = ctx.max_seen_text[ctx.active_turn_baseline_len:] if ctx.max_seen_text else ""

        # ğŸ†• ===== æœ€ç»ˆå›¾ç‰‡æå– =====
        if self._image_extraction_enabled and (ctx.images_detected or final_snap.get('has_images')):
            images = self._extract_final_images(selector, ctx)
            if images:
                self._final_images = images
                logger.debug(f"[Final] æå–åˆ° {len(images)} å¼ å›¾ç‰‡")

                logger.debug("[Final] å·²æå–å›¾ç‰‡ï¼Œä½†å·²ç¦ç”¨ StreamMonitor å›¾ç‰‡ chunk è¾“å‡ºï¼ˆç”± BrowserCore ç»Ÿä¸€å‘é€æœ¬åœ°å›¾ç‰‡ï¼‰")

        logger.debug(f"æµå¼ç›‘å¬ç»“æŸ: {ctx.sent_content_length}å­—ç¬¦, {len(self._final_images)}å¼ å›¾ç‰‡")

    def _extract_final_images(self, selector: str, ctx: StreamContext) -> List[Dict]:
        """
        ğŸ†• æå–æœ€ç»ˆå›¾ç‰‡ï¼ˆå¸¦è¶…æ—¶ä¿æŠ¤ï¼‰
        """
        if not self._image_extraction_enabled:
            return []
        
        # ğŸ†• è¶…æ—¶ä¿æŠ¤ï¼šé»˜è®¤ 5 ç§’ï¼Œå¯é€šè¿‡é…ç½®è¦†ç›–
        timeout = self._image_config.get("extraction_timeout", 5.0)
        

        
        result_container = {"images": []}
        extraction_error = {"error": None}
        
        def extract_with_timeout():
            """åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­æ‰§è¡Œæå–"""
            try:
                eles = self.finder.find_all(selector, timeout=1)
                if not eles:
                    return
                
                target = eles[-1]
                
                # ä½¿ç”¨æå–å™¨çš„ extract_images æ–¹æ³•
                if hasattr(self.extractor, 'extract_images'):
                    images = self.extractor.extract_images(
                        target,
                        config=self._image_config,
                        container_selector_fallback=selector
                    )
                    result_container["images"] = images
            
            except Exception as e:
                extraction_error["error"] = e
        
        try:
            # å¯åŠ¨æå–çº¿ç¨‹
            extraction_thread = threading.Thread(target=extract_with_timeout, daemon=True)
            extraction_thread.start()
            
            # ç­‰å¾…è¶…æ—¶
            extraction_thread.join(timeout=timeout)
            
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if extraction_thread.is_alive():
                logger.warning(f"[Final] å›¾ç‰‡æå–è¶…æ—¶ï¼ˆ{timeout}sï¼‰ï¼Œè·³è¿‡")
                return []
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if extraction_error["error"]:
                raise extraction_error["error"]
            
            return result_container["images"]
        
        except Exception as e:
            logger.error(f"[Final] å›¾ç‰‡æå–å¤±è´¥: {e}")
            return []
    
    def get_final_images(self) -> List[Dict]:
        """è·å–æœ€ç»ˆæå–çš„å›¾ç‰‡ï¼ˆä¾›å¤–éƒ¨è°ƒç”¨ï¼‰"""
        return self._final_images


__all__ = ['StreamContext', 'GeneratingStatusCache', 'StreamMonitor']